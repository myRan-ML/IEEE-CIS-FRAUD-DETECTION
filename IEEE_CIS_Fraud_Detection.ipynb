{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, auc, get_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator, IterativeImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau, ttest_ind, chisquare\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "from plotnine import ggplot, aes, geom_histogram, \\\n",
    "                     theme_tufte, labs, element_text, \\\n",
    "                     theme, element_line, scale_y_continuous, \\\n",
    "                     facet_wrap, after_stat, labeller\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random_state = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount into drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62943ec",
   "metadata": {},
   "source": [
    "如果在本地机器上运行，请将 `data_directory` 变量修改为 IEEE-CIS 欺诈检测数据集所在的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b84df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"./data/\"\n",
    "\n",
    "train_identity = pd.read_csv(data_directory + \"train_identity.csv\")\n",
    "train_transaction = pd.read_csv(data_directory + \"train_transaction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89540337",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed48db0",
   "metadata": {},
   "source": [
    "# 数据说明\n",
    "来自`train_transaction.csv`：\n",
    "\n",
    "`TransactionDT`：距离某个参考时间点的时间差（不是实际时间戳）\n",
    "`TransactionAMT`：交易金额（美元）\n",
    "`ProductCD`：产品代码，每笔交易的产品类型\n",
    "`card1 - card6`：支付卡信息，如卡类型、卡类别、发卡银行、国家等\n",
    "`addr`：地址\n",
    "`dist`：距离\n",
    "`P_` 和 `(R_)` `emaildomain`：购买者和收件人的邮箱域名\n",
    "`C1 - C14`：计数特征，如与支付卡关联的地址数量等，具体含义已被隐藏\n",
    "`D1 - D15`：时间差特征，如与前一笔交易的天数等\n",
    "`M1 - M9`：匹配特征，如卡和地址上的姓名是否一致等\n",
    "`Vxxx`：Vesta 工程化的丰富特征，包括排名、计数及其他实体关系\n",
    "\n",
    "\n",
    "来自 `train_identity.csv`：\n",
    "\n",
    "`id01 - id11`：身份相关的数值特征，由 Vesta 及其安全合作伙伴收集，如设备评分、IP 域评分、代理评分等，也记录了行为指纹（如账户登录次数/失败次数、停留时长等），由于合作条款无法详细说明\n",
    "`id_30`：设备操作系统\n",
    "`id_31`：设备使用的网页浏览器\n",
    "`id_33`：设备屏幕分辨率\n",
    "`DeviceType`：设备类型，可能为 mobile 或 desktop\n",
    "`DeviceInfo`：设备及其操作系统的综合信息\n",
    "本表中的变量为身份信息——与交易相关的网络连接信息（IP、ISP、代理等）和数字签名（UA/浏览器/操作系统/版本等）。\n",
    "这些信息由 Vesta 的反欺诈系统和数字安全合作伙伴收集。\n",
    "（字段名称已被隐藏，且不会提供一一对应的字典，以保护隐私和遵守合同协议）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773ee1a",
   "metadata": {},
   "source": [
    "## 特征工程\n",
    "\n",
    "由于本数据集包含 400 多个特征，无法全部进行分析，因此使用如下参数（n_estimators=1000, max_depth=10, class_weight={0: 5, 1: 95}, min_samples_split=32, min_samples_leaf=32）训练了一个随机森林模型，并选取了对模型最重要的前 6 个特征。按重要性排序，这些特征分别是：C14、C13、V264、V317、V258、V294、V257 和 C4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a44e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./drive/My Drive/ieee-fraud-detection/output/feature_importances.csv\", index_col = 0)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261540cc",
   "metadata": {},
   "source": [
    "## 无监督特征分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db87794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_hist(feature, bins=30):\n",
    "  return ggplot(train_transaction, aes(x=feature)) + geom_histogram(bins = bins) + \\\n",
    "    labs(title=f\"Distribution of Feature {feature}\",  x=f\"Value of {feature}\", y=\"Frequency\") + \\\n",
    "    theme_tufte() + \\\n",
    "    theme(panel_grid_major_y = element_line(color=\".9\"),\n",
    "          panel_grid_minor_y = element_line(color=\".9\")) + \\\n",
    "    scale_y_continuous(trans='log10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7961f8",
   "metadata": {},
   "source": [
    "### C14\n",
    "\n",
    "`C14`基本上是双峰分布。在数值为 `1.0` 处有一个巨大的峰值，随后频率迅速下降，直到在数值为 `110` 处又出现一个较小的次峰。从直方图来看，数据中可能还存在其他局部峰值，但这两个峰最为显著。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.C14.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0152bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('C14', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8add5cd8",
   "metadata": {},
   "source": [
    "### C13\n",
    "\n",
    "`C13` 是单峰分布。其数值在` 1.0 `处达到峰值，之后逐渐下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.C14.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd33186",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('C13', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be8f11",
   "metadata": {},
   "source": [
    "### V264\n",
    "\n",
    "`V264 `是多峰分布。最大峰值出现在` 0.0`，但在看似规律的区间（如 50、100、150、200 等）还会出现许多其他局部峰值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.V264.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('V264', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfdd3e",
   "metadata": {},
   "source": [
    "### V317\n",
    "\n",
    "`V317`是多峰分布，其中大多数数据（如下面分位数所示，超过 80%）集中在`0.0`。其他峰值分散在不同的数值区间，如直方图所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.V317.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f694491",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('V317', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5170f494",
   "metadata": {},
   "source": [
    "### V258\n",
    "\n",
    "`V258` 是单峰且右偏分布。绝大多数取值为 `1.0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.V258.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef4235",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('V258', bins=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af21a0b",
   "metadata": {},
   "source": [
    "### V294\n",
    "\n",
    "`V294` 在 `0.0` 处有一个陡峭的峰值，随后迅速下降。大多数取值为 `0.0`。不过，从直方图来看，在大约 `700-800` 区间还有一个较小的次峰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.V294.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d987a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('V294', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e0632",
   "metadata": {},
   "source": [
    "### C8\n",
    "\n",
    "另一个严重右偏的特征。从分位数可以看出，`90%`以上的数据取值小于或等于 `1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc658397",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.C8.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('C8', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed866e1",
   "metadata": {},
   "source": [
    "### V318\n",
    "\n",
    "超过 90% 的数据取值为 `0.0`，但也存在一些离群值。该分布是单峰且右偏的，这与我们这里的大多数特征类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb34199",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.V318.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('V318', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26517723",
   "metadata": {},
   "source": [
    "### V257\n",
    "\n",
    "从分位数可以看出，超过 80% 的取值小于或等于 `1.0`。该分布同样是单峰且右偏的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.V257.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce74155",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('V257', bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac47f5b",
   "metadata": {},
   "source": [
    "### C4\n",
    "\n",
    "从分位数可以看出，超过 90% 的取值小于或等于 `1.0`。该分布同样是右偏的，但在较大取值处存在一些小的局部峰值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.C4.quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169cc18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_hist('C4', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91ffa9",
   "metadata": {},
   "source": [
    "## 有监督的特征分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15df6e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_hist(feature, bins=30):\n",
    "  return ggplot(train_transaction, aes(x=feature, y=after_stat(\"density\"))) + geom_histogram(bins = bins) + \\\n",
    "    labs(title=f\"Distribution of Feature {feature}\",  x=f\"Value of {feature}\", y=\"Density\") + \\\n",
    "    theme_tufte() + \\\n",
    "    theme(panel_grid_major_y = element_line(color=\".9\"),\n",
    "          panel_grid_minor_y = element_line(color=\".9\")) + \\\n",
    "    scale_y_continuous(trans='log10') + \\\n",
    "    facet_wrap(\"isFraud\", labeller=labeller(cols = lambda x : \"Fraud\" if x == '1' else \"Not Fraud\"))\n",
    "\n",
    "\n",
    "def supervised_analysis(dataframe, features, y_column):\n",
    "  pearson = []\n",
    "  spearman = []\n",
    "  kendall_tau = []\n",
    "  test_type = []\n",
    "  statistic = []\n",
    "  p_value = []\n",
    "\n",
    "  features = list(features)\n",
    "\n",
    "  if y_column in features:\n",
    "    features.remove(y_column)\n",
    "\n",
    "  for feature in tqdm(features):\n",
    "\n",
    "    temp_df = dataframe[[\"isFraud\", feature]].dropna()\n",
    "\n",
    "    numeric = False if temp_df[feature].dtype == \"object\" else True\n",
    "\n",
    "    normal = temp_df[temp_df[y_column] == 0][feature]\n",
    "    fraud = temp_df[temp_df[y_column] == 1][feature]\n",
    "\n",
    "    if numeric:\n",
    "      feature_as_float = temp_df[feature] = temp_df[feature].astype(float)\n",
    "      # Various Correlations\n",
    "      pearson.append(pearsonr(temp_df[y_column], feature_as_float)[0])\n",
    "      spearman.append(spearmanr(temp_df[y_column], feature_as_float)[0])\n",
    "      kendall_tau.append(kendalltau(temp_df[y_column], feature_as_float)[0])\n",
    "\n",
    "      # Student T-Test\n",
    "      t = ttest_ind(normal, fraud)\n",
    "      test_type.append(\"Student T-Test\")\n",
    "      p_value.append(t.pvalue)\n",
    "      statistic.append(t.statistic)\n",
    "    else:\n",
    "      pearson.append(np.NaN)\n",
    "      spearman.append(np.NaN)\n",
    "      kendall_tau.append(np.NaN)\n",
    "\n",
    "      observed_counter = Counter(fraud)\n",
    "      expected_counter = Counter(normal)\n",
    "\n",
    "      keys = set(observed_counter.keys()).union(set(expected_counter.keys()))\n",
    "      keys = list(sorted(keys))\n",
    "\n",
    "      observed = np.array([observed_counter[key] for key in keys])\n",
    "      expected = np.array([expected_counter[key] for key in keys])\n",
    "\n",
    "      scale_factor = np.sum(expected) / np.sum(observed)\n",
    "      observed_adjusted = observed * scale_factor\n",
    "\n",
    "      expected[expected == 0] = 1e-10\n",
    "\n",
    "      # Chi-Squared test\n",
    "      cs = chisquare(f_obs=observed_adjusted, f_exp=expected)\n",
    "      test_type.append(\"Chi-Squared\")\n",
    "      p_value.append(cs.pvalue)\n",
    "      statistic.append(cs.statistic)\n",
    "\n",
    "  results = {\n",
    "      \"Top Features\" : features,\n",
    "      \"Pearson Correlation\" : pearson,\n",
    "      \"Spearman Ranked\" : spearman,\n",
    "      \"Kendall-Tau\" : kendall_tau,\n",
    "      \"Test Type\": test_type,\n",
    "      \"Statistic\": statistic,\n",
    "      \"P-Value\" : p_value\n",
    "      }\n",
    "\n",
    "  return pd.DataFrame(results)\n",
    "\n",
    "if not os.path.isfile(\"./drive/My Drive/ieee-fraud-detection/output/supervised_feature_analysis.csv\"):\n",
    "  whole = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "  analysis = supervised_analysis(whole, whole.columns, \"isFraud\")\n",
    "  analysis.to_csv(\"./drive/My Drive/ieee-fraud-detection/output/supervised_feature_analysis.csv\")\n",
    "else:\n",
    "  analysis = pd.read_csv(\"./drive/My Drive/ieee-fraud-detection/output/supervised_feature_analysis.csv\")\n",
    "\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34492921",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = [\"C14\", \"C13\", \"V264\", \"V317\", \"V258\", \"V294\", \"C8\", \"V318\"]\n",
    "\n",
    "supervised_analysis(train_transaction, top_features, \"isFraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdaeeab",
   "metadata": {},
   "source": [
    "### C14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b01f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"C14\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff586001",
   "metadata": {},
   "source": [
    "### C13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be927346",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"C13\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67527716",
   "metadata": {},
   "source": [
    "### V264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73330c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"V264\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d778f5",
   "metadata": {},
   "source": [
    "### V317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a67dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"V317\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f75d6f",
   "metadata": {},
   "source": [
    "### V258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17766fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"V258\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8a71cb",
   "metadata": {},
   "source": [
    "### V294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac53cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"V294\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1a71e",
   "metadata": {},
   "source": [
    "### C8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb25547",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"C8\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e86e89",
   "metadata": {},
   "source": [
    "### V318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"V318\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb127a6",
   "metadata": {},
   "source": [
    "### V257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a510256",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"V257\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74fde1d",
   "metadata": {},
   "source": [
    "### C4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_hist(\"C4\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c40f51",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "\n",
    "我们首先将训练数据集中的各个特征合并为一个单一的 DataFrame，然后将其划分为训练集、测试集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b22cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "\n",
    "# one hot encode the categorical variables\n",
    "\n",
    "whole = whole.sort_values(by=\"TransactionDT\")\n",
    "\n",
    "X = whole[whole.columns.difference(['isFraud'])]\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = whole['isFraud']\n",
    "\n",
    "n = len(whole)\n",
    "\n",
    "del whole\n",
    "\n",
    "X_train = X[:-int(n * 0.2)]\n",
    "X_test = X[-int(n * 0.2):]\n",
    "\n",
    "y_train = y[:-int(n * 0.2)]\n",
    "y_test = y[-int(n * 0.2):]\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136829ad",
   "metadata": {},
   "source": [
    "## 数据填充"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057c341",
   "metadata": {},
   "source": [
    "### 均值/中位数/众数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_impute(X, impute_method = \"mean\"):\n",
    "  preprocessor = ColumnTransformer(\n",
    "      transformers=[\n",
    "          (\"num\", SimpleImputer(strategy=impute_method),\n",
    "           selector(dtype_exclude=\"object\")),\n",
    "          (\"cat\", SimpleImputer(strategy=\"most_frequent\"),\n",
    "           selector(dtype_include=\"object\")),\n",
    "      ]\n",
    "  )\n",
    "\n",
    "  preprocessor.fit(X)\n",
    "\n",
    "  imputed_values = pd.DataFrame(preprocessor.transform(X),\n",
    "                                columns=X.columns)\n",
    "\n",
    "  ind_names = [name + \"_ind\" for name in X.columns]\n",
    "  indicators = pd.DataFrame(MissingIndicator(features=\"all\").fit_transform(X),\n",
    "                            columns=ind_names)\n",
    "\n",
    "  return pd.concat([imputed_values, indicators], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "whole = whole.sort_values(by=\"TransactionDT\")\n",
    "\n",
    "X = whole[whole.columns.difference(['isFraud'])]\n",
    "y = whole['isFraud']\n",
    "\n",
    "del whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf362cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"./drive/My Drive/ieee-fraud-detection/interpolated/mean_interpolated.csv\"\n",
    "if not os.path.isfile(save_location):\n",
    "  X_mean = basic_impute(X)\n",
    "  X_mean.to_csv(save_location)\n",
    "  del X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"./drive/My Drive/ieee-fraud-detection/interpolated/median_interpolated.csv\"\n",
    "if not os.path.isfile(save_location):\n",
    "  X_median = basic_impute(X, impute_method = \"median\")\n",
    "  X_median.to_csv(save_location)\n",
    "  del X_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcac1d",
   "metadata": {},
   "source": [
    "### 多重插补法（MICE，多变量链式插补）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000146ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mice_impute(X, iterations=10):\n",
    "  preprocessor = ColumnTransformer(\n",
    "      transformers=[\n",
    "          (\"num\",IterativeImputer(max_iter=iterations,\n",
    "                                  random_state=random_state),\n",
    "           selector(dtype_exclude=\"object\")),\n",
    "          (\"cat\", SimpleImputer(strategy=\"most_frequent\"),\n",
    "           selector(dtype_include=\"object\")),\n",
    "      ]\n",
    "  )\n",
    "\n",
    "  imputed_values = pd.DataFrame(preprocessor.fit_transform(X),\n",
    "                                columns=X.columns)\n",
    "\n",
    "  ind_names = [name + \"_ind\" for name in X.columns]\n",
    "  indicators = pd.DataFrame(MissingIndicator(features=\"all\").fit_transform(X),\n",
    "                            columns=ind_names)\n",
    "\n",
    "  return pd.concat([imputed_values, indicators], axis = 1)\n",
    "\n",
    "\n",
    "save_location = \"./drive/My Drive/ieee-fraud-detection/interpolated/mice_interpolated.csv\"\n",
    "if not os.path.isfile(save_location):\n",
    "  X_mice = mice_impute(X)\n",
    "  X_mice.to_csv(save_location)\n",
    "  del X_mice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251355d7",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d630a1",
   "metadata": {},
   "source": [
    "## Helper Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_untested_combos(parameters, csv_location = None):\n",
    "  \"\"\"find all the untested combos of parameters for a grid search\"\"\"\n",
    "  parameter_combos = [{k:v for k, v in zip(parameters.keys(), row)} for row in product(*parameters.values())]\n",
    "\n",
    "  if not csv_location or not os.path.isfile(csv_location):\n",
    "    print(f\"Untested combos: No csv found...\")\n",
    "    return parameter_combos\n",
    "\n",
    "  existing_output = []\n",
    "  with open(csv_location) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        existing_output.append(row)\n",
    "\n",
    "  def process(x):\n",
    "    if x.isnumeric() or \"{\" in x or \"(\" in x or \\\n",
    "       (x.count(\".\") == 1 and x.replace(\".\", \"\").isnumeric()):\n",
    "      return literal_eval(x)\n",
    "    else:\n",
    "      return x\n",
    "\n",
    "  exclude = [{k : process(v) for k, v in row.items() if k in parameters.keys()} for row in existing_output]\n",
    "\n",
    "  print(exclude)\n",
    "\n",
    "  untested_combos = []\n",
    "  for combo in parameter_combos:\n",
    "    match = False\n",
    "    for exclusion in exclude:\n",
    "      for i, parameter in enumerate(parameters.keys()):\n",
    "        if combo[parameter] != exclusion[parameter]:\n",
    "          break\n",
    "        elif i == len(parameters.keys()) - 1:\n",
    "          match = True\n",
    "      if match:\n",
    "        break\n",
    "    if not match:\n",
    "      untested_combos.append(combo)\n",
    "\n",
    "  print(untested_combos)\n",
    "\n",
    "  return untested_combos\n",
    "\n",
    "def run_grid_search(classifier, X, y, combos, scoring_metric, csv_location,\n",
    "                    load_csv_stub, cv = 5):\n",
    "\n",
    "  X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "  current_impute = None\n",
    "  for parameter_dict in combos:\n",
    "\n",
    "    if \"impute_strat\" in parameter_dict:\n",
    "      if current_impute != parameter_dict[\"impute_strat\"]:\n",
    "        csv_file = load_csv_stub + parameter_dict[\"impute_strat\"] + \"_interpolated.csv\"\n",
    "        current_impute = parameter_dict[\"impute_strat\"]\n",
    "        del X\n",
    "        X = pd.get_dummies(pd.read_csv(csv_file)[:-int(n * 0.2)], drop_first=True)\n",
    "      del parameter_dict[\"impute_strat\"]\n",
    "\n",
    "    clf = classifier(**parameter_dict)\n",
    "\n",
    "    n = len(X)\n",
    "    unit = int(n / cv)\n",
    "\n",
    "    scores = {\n",
    "          \"training_score\" : [],\n",
    "          \"validation_score\" : []\n",
    "      }\n",
    "\n",
    "    scorer = get_scorer(scoring_metric)._score_func\n",
    "\n",
    "    for i in range(cv - 1):\n",
    "      index = (i + 1) * unit\n",
    "      X_train = X[index - unit:index]\n",
    "      y_train = y[index - unit:index]\n",
    "      X_val = X[index:index + unit]\n",
    "      y_val = y[index:index + unit]\n",
    "\n",
    "      if \"class_weight\" in parameter_dict:\n",
    "        weights = [parameter_dict[\"class_weight\"][x] for x in y_train]\n",
    "      else:\n",
    "          weights = [1] * len(y_train)\n",
    "\n",
    "      if classifier is XGBClassifier:\n",
    "        clf.fit(X_train, y_train, sample_weight=weights)\n",
    "      else:\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "      y_pred_train = clf.predict(X_train)\n",
    "      y_pred_val = clf.predict(X_val)\n",
    "\n",
    "      training_score = scorer(y_train, y_pred_train)\n",
    "      scores[\"training_score\"].append(training_score)\n",
    "\n",
    "      validation_score = scorer(y_val, y_pred_val)\n",
    "      scores[\"validation_score\"].append(validation_score)\n",
    "\n",
    "    if current_impute:\n",
    "      parameter_dict.update({\"impute_strat\" : current_impute})\n",
    "\n",
    "    parameter_dict.update({\"scoring_metric\" : scoring_metric})\n",
    "\n",
    "    score_means = {key : mean(value) for key, value in scores.items()}\n",
    "    parameter_dict.update(score_means)\n",
    "\n",
    "    if not os.path.isfile(csv_location):\n",
    "        print(f\"File {csv_location} does not exist, creating...\")\n",
    "        print(f\"results: {parameter_dict}\")\n",
    "        with open(csv_location, 'w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile,\n",
    "                                    fieldnames=parameter_dict.keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerow(parameter_dict)\n",
    "    else:\n",
    "        print(f\"Appending results to {csv_location}...\")\n",
    "        print(f\"results: {parameter_dict}\")\n",
    "        with open(csv_location, 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile,\n",
    "                                    fieldnames=parameter_dict.keys())\n",
    "            writer.writerow(parameter_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fcf28a",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'impute_strat' : ['mean', 'median', 'mice'],\n",
    "    'C' : [100, 10, 1, 0.1, .01, .001],\n",
    "    'class_weight' : [{0: 1, 1: 1},  {0: 1, 1: 10}, {0: 1, 1: 20},\n",
    "                      {0: 1, 1: 30}, {0: 1, 1: 40}, {0: 1, 1: 50},\n",
    "                      {0: 1, 1: 60}, {0: 1, 1: 70}, {0: 1, 1: 80},\n",
    "                      {0: 1, 1: 90}]\n",
    "}\n",
    "scoring_metric = 'average_precision'\n",
    "\n",
    "untested_combos = find_untested_combos(parameters, \"./drive/My Drive/ieee-fraud-detection/output/lr_results.csv\")\n",
    "run_grid_search(LogisticRegression, X_train, y_train, untested_combos, scoring_metric,\n",
    "                csv_location=\"./drive/My Drive/ieee-fraud-detection/output/lr_results.csv\",\n",
    "                load_csv_stub=\"./drive/My Drive/ieee-fraud-detection/interpolated/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d32252",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./drive/My Drive/ieee-fraud-detection/output/lr_results.csv\")\\\n",
    ".sort_values(by=\"validation_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca874ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "whole = whole.sort_values(by=\"TransactionDT\")\n",
    "\n",
    "csv_file = \"./drive/My Drive/ieee-fraud-detection/interpolated/median_interpolated.csv\"\n",
    "X = pd.read_csv(csv_file).sort_values(by=\"TransactionDT\")\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = whole['isFraud']\n",
    "\n",
    "n = len(whole)\n",
    "\n",
    "del whole\n",
    "\n",
    "X_train = X[:-int(n * 0.2)]\n",
    "X_test = X[-int(n * 0.2):]\n",
    "\n",
    "y_train = y[:-int(n * 0.2)]\n",
    "y_test = y[-int(n * 0.2):]\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 100, class_weight={0: 1, 1: 10})\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d346bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "y_prob_train = clf.predict_proba(X_train)[:,1]\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_prob_test = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa29c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_prediction = pd.DataFrame({\n",
    "    \"actual\" : y_test,\n",
    "    \"probability\" : y_prob_test\n",
    "}).sort_values(by=\"probability\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642bf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_lr = {\n",
    "    \"Model\" : \"Logistic Regression\",\n",
    "    \"Train AUC\" : roc_auc_score(y_train, y_prob_train),\n",
    "    \"Test AUC\" : roc_auc_score(y_test, y_prob_test),\n",
    "    \"Train PR AUC\" : average_precision_score(y_train, y_prob_train),\n",
    "    \"Test PR AUC\" : average_precision_score(y_test, y_prob_test),\n",
    "    \"Precision K5\": np.mean(prob_prediction.actual[:5]),\n",
    "    \"Precision K10\": np.mean(prob_prediction.actual[:10]),\n",
    "}\n",
    "\n",
    "metrics_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56034b",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = list(reversed([2 ** i for i in range(4, 10)]))\n",
    "options = options + [0]\n",
    "\n",
    "layer_combos = []\n",
    "for i, layer_1 in enumerate(options[:-1]):\n",
    "  for j, layer_2 in enumerate(options[i:]):\n",
    "    if layer_2 == 0:\n",
    "      layer_combos.append((layer_1,))\n",
    "      continue\n",
    "    for layer_3 in options[i+j:]:\n",
    "      if layer_3 == 0:\n",
    "        layer_combos.append((layer_1, layer_2))\n",
    "        continue\n",
    "      layer_combos.append((layer_1, layer_2, layer_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'impute_strat' : ['mean', 'median', 'mice'],\n",
    "    'hidden_layer_sizes' : layer_combos,\n",
    "    'max_iter' : [50]\n",
    "}\n",
    "scoring_metric = 'average_precision'\n",
    "\n",
    "untested_combos = find_untested_combos(parameters, \"./drive/My Drive/ieee-fraud-detection/output/mlp_results.csv\")\n",
    "run_grid_search(MLPClassifier, X_train, y_train, untested_combos, scoring_metric,\n",
    "                csv_location=\"./drive/My Drive/ieee-fraud-detection/output/mlp_results.csv\",\n",
    "                load_csv_stub=\"./drive/My Drive/ieee-fraud-detection/interpolated/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./drive/My Drive/ieee-fraud-detection/output/mlp_results.csv\")\\\n",
    ".sort_values(by=\"validation_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "whole = whole.sort_values(by=\"TransactionDT\")\n",
    "\n",
    "csv_file = \"./drive/My Drive/ieee-fraud-detection/interpolated/mice_interpolated.csv\"\n",
    "X = pd.read_csv(csv_file).sort_values(by=\"TransactionDT\")\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = whole['isFraud']\n",
    "\n",
    "n = len(whole)\n",
    "\n",
    "del whole\n",
    "\n",
    "X_train = X[:-int(n * 0.2)]\n",
    "X_test = X[-int(n * 0.2):]\n",
    "\n",
    "y_train = y[:-int(n * 0.2)]\n",
    "y_test = y[-int(n * 0.2):]\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(256, 256), max_iter=200)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f902392",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "y_prob_train = clf.predict_proba(X_train)[:,1]\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_prob_test = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee440bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_prediction = pd.DataFrame({\n",
    "    \"actual\" : y_test,\n",
    "    \"probability\" : y_prob_test\n",
    "}).sort_values(by=\"probability\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f533a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mlp = {\n",
    "    \"Model\" : \"Multi-Layer Perceptron\",\n",
    "    \"Train AUC\" : roc_auc_score(y_train, y_prob_train),\n",
    "    \"Test AUC\" : roc_auc_score(y_test, y_prob_test),\n",
    "    \"Train PR AUC\" : average_precision_score(y_train, y_prob_train),\n",
    "    \"Test PR AUC\" : average_precision_score(y_test, y_prob_test),\n",
    "    \"Precision K5\": np.mean(prob_prediction.actual[:5]),\n",
    "    \"Precision K10\": np.mean(prob_prediction.actual[:10]),\n",
    "}\n",
    "\n",
    "metrics_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa83ec",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dae5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators' : [100, 1000],\n",
    "    'criterion' : ['gini'],\n",
    "    'max_depth' : [10],\n",
    "    'class_weight' : [{0: 1, 1: 10}, {0: 1, 1: 20}, {0: 1, 1: 30},\n",
    "                      {0: 1, 1: 40}, {0: 1, 1: 50}, {0: 1, 1: 60},\n",
    "                      {0: 1, 1: 70}, {0: 1, 1: 80}, {0: 1, 1: 90}],\n",
    "    'min_samples_split' : [32],\n",
    "    'min_samples_leaf' : [32]\n",
    "}\n",
    "\n",
    "scoring_metric = 'average_precision'\n",
    "\n",
    "untested_combos = find_untested_combos(parameters, \"./drive/My Drive/ieee-fraud-detection/output/rf_results.csv\")\n",
    "run_grid_search(RandomForestClassifier, X_train, y_train, untested_combos,\n",
    "                scoring_metric, csv_location=\"./drive/My Drive/ieee-fraud-detection/output/rf_results.csv\",\n",
    "                load_csv_stub=\"./drive/My Drive/ieee-fraud-detection/interpolated/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ce2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./drive/My Drive/ieee-fraud-detection/output/rf_results.csv\")\\\n",
    ".sort_values(by=\"validation_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946369bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "whole = whole.sort_values(by=\"TransactionDT\")\n",
    "\n",
    "X = whole[whole.columns.difference(['isFraud'])]\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = whole['isFraud']\n",
    "\n",
    "n = len(whole)\n",
    "\n",
    "del whole\n",
    "\n",
    "X_train = X[:-int(n * 0.2)]\n",
    "X_test = X[-int(n * 0.2):]\n",
    "\n",
    "y_train = y[:-int(n * 0.2)]\n",
    "y_test = y[-int(n * 0.2):]\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6249449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, criterion=\"gini\", max_depth=10,\n",
    "                             class_weight={0: 1, 1: 10}, min_samples_split=32,\n",
    "                             min_samples_leaf=32)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "y_prob_train = clf.predict_proba(X_train)[:,1]\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_prob_test = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_prediction = pd.DataFrame({\n",
    "    \"actual\" : y_test,\n",
    "    \"probability\" : y_prob_test\n",
    "}).sort_values(by=\"probability\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rf = {\n",
    "    \"Model\" : \"Random Forest\",\n",
    "    \"Train AUC\" : roc_auc_score(y_train, y_prob_train),\n",
    "    \"Test AUC\" : roc_auc_score(y_test, y_prob_test),\n",
    "    \"Train PR AUC\" : average_precision_score(y_train, y_prob_train),\n",
    "    \"Test PR AUC\" : average_precision_score(y_test, y_prob_test),\n",
    "    \"Precision K5\": np.mean(prob_prediction.actual[:5]),\n",
    "    \"Precision K10\": np.mean(prob_prediction.actual[:10]),\n",
    "}\n",
    "\n",
    "metrics_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb8feda",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd275b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'learning_rate' : [0.1, 1],\n",
    "    'max_iter' : [50, 100, 200],\n",
    "    'max_depth' : [1, 2, 4, 6, 8, 10],\n",
    "    'class_weight' : [{0: 1, 1: 1},  {0: 1, 1: 10}, {0: 1, 1: 20},\n",
    "                      {0: 1, 1: 30}, {0: 1, 1: 40}, {0: 1, 1: 50},\n",
    "                      {0: 1, 1: 60}, {0: 1, 1: 70}, {0: 1, 1: 80},\n",
    "                      {0: 1, 1: 90}]\n",
    "}\n",
    "\n",
    "untested_combos = find_untested_combos(parameters, \"./drive/My Drive/ieee-fraud-detection/output/xgb_results.csv\")\n",
    "run_grid_search(XGBClassifier, X_train, y_train, untested_combos,\n",
    "                scoring_metric=\"average_precision\",\n",
    "                csv_location=\"./drive/My Drive/ieee-fraud-detection/output/xgb_results.csv\",\n",
    "                load_csv_stub=\"./drive/My Drive/ieee-fraud-detection/interpolated/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./drive/My Drive/ieee-fraud-detection/output/xgb_results.csv\")\\\n",
    ".sort_values(by=\"validation_score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5496d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "whole = whole.sort_values(by=\"TransactionDT\")\n",
    "\n",
    "X = whole[whole.columns.difference(['isFraud'])]\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = whole['isFraud']\n",
    "\n",
    "n = len(whole)\n",
    "\n",
    "del whole\n",
    "\n",
    "X_train = X[:-int(n * 0.2)]\n",
    "X_test = X[-int(n * 0.2):]\n",
    "\n",
    "y_train = y[:-int(n * 0.2)]\n",
    "y_test = y[-int(n * 0.2):]\n",
    "\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b28f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(learning_rate=0.1, max_iter=200, max_depth=10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "y_prob_train = clf.predict_proba(X_train)[:,1]\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_prob_test = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf49820",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_prediction = pd.DataFrame({\n",
    "    \"actual\" : y_test,\n",
    "    \"probability\" : y_prob_test\n",
    "}).sort_values(by=\"probability\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8336730",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_xgb = {\n",
    "    \"Model\" : \"XGBoost\",\n",
    "    \"Train AUC\" : roc_auc_score(y_train, y_prob_train),\n",
    "    \"Test AUC\" : roc_auc_score(y_test, y_prob_test),\n",
    "    \"Train PR AUC\" : average_precision_score(y_train, y_prob_train),\n",
    "    \"Test PR AUC\" : average_precision_score(y_test, y_prob_test),\n",
    "    \"Precision K5\": np.mean(prob_prediction.actual[:5]),\n",
    "    \"Precision K10\": np.mean(prob_prediction.actual[:10]),\n",
    "}\n",
    "\n",
    "metrics_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20aecb8",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfca4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([metrics_lr, metrics_mlp, metrics_rf, metrics_xgb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detect-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
